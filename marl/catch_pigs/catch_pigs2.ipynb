{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coordinated-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from env_CatchPigs import EnvCatchPigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "completed-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, size, obs_dims):\n",
    "        self.mem_size = size\n",
    "        self.obs_mem = torch.zeros((self.mem_size, *obs_dims))\n",
    "        self.act_mem = torch.zeros(self.mem_size, dtype=torch.int64)\n",
    "        self.rew_mem = torch.zeros(self.mem_size, dtype=torch.float32)\n",
    "        self.next_obs_mem = torch.zeros((self.mem_size, *obs_dims))\n",
    "        self.done_mem = torch.zeros(self.mem_size, dtype=torch.bool)\n",
    "        self.cntr = 0\n",
    "\n",
    "    def push(self, obs, act, rew, next_obs, done):\n",
    "        \"\"\"\n",
    "        obs :: torch tensor shape==(channels, height, width)\n",
    "        act :: int\n",
    "        rew :: int\n",
    "        obs_ :: torch tensor shape==(channels, height, width)\n",
    "        done :: bool\n",
    "        \"\"\"\n",
    "\n",
    "        idx = self.cntr % self.mem_size\n",
    "        self.obs_mem[idx] = obs\n",
    "        self.act_mem[idx] = act\n",
    "        self.rew_mem[idx] = rew\n",
    "        self.next_obs_mem[idx] = next_obs\n",
    "        self.done_mem[idx] = done \n",
    "        self.cntr += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        max_idx = min(self.mem_size, self.cntr)\n",
    "        idxs = np.random.choice(max_idx, batch_size, replace=False)\n",
    "        obs_batch = self.obs_mem[idxs]\n",
    "        act_batch = self.act_mem[idxs]\n",
    "        rew_batch = self.rew_mem[idxs]\n",
    "        next_obs_batch = self.next_obs_mem[idxs]\n",
    "        done_batch = self.done_mem[idxs]\n",
    "\n",
    "        return obs_batch, act_batch, rew_batch, next_obs_batch, done_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungarian-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, obs_dims, num_acts, lr=1e-3):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(obs_dims[0], 32, 4, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 2, stride=1)\n",
    "        \n",
    "        linear_input_dims = self._calc_conv_output_dims(obs_dims)\n",
    "        \n",
    "        self.linear1 = nn.Linear(linear_input_dims, 512)\n",
    "        self.linear2 = nn.Linear(512, num_acts)\n",
    "        \n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "        \n",
    "    def _calc_conv_output_dims(self, input_dims):\n",
    "        tmp = torch.zeros((1, *input_dims))\n",
    "        tmp = self.conv1(tmp)\n",
    "        tmp = self.conv2(tmp)\n",
    "        tmp = self.conv3(tmp)\n",
    "        return int(np.prod(tmp.size()))\n",
    "    \n",
    "    \n",
    "    def forward(self, obs):\n",
    "        h = F.relu(self.conv1(obs))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        # flatten conv layer output\n",
    "        h = h.view(h.size()[0], -1)\n",
    "        # conv_state shape is BS x (n_filters * H * W)\n",
    "        h = F.relu(self.linear1(h))\n",
    "        acts = self.linear2(h)\n",
    "\n",
    "        return acts\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composite-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "    def __init__(self, obs_dims, num_acts, gamma=0.99, epsilon=1, lr=0.01,\n",
    "                 mem_size=10000, batch_size=32, eps_min=0.01, eps_dec=7e-5,\n",
    "                 replace=100, chkpt_dir='tmp/dqn'):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.num_acts = num_acts\n",
    "        self.obs_dims = obs_dims\n",
    "        self.batch_size = batch_size\n",
    "        self.eps_min = eps_min\n",
    "        self.eps_dec = eps_dec\n",
    "        self.replace_target_cnt = replace\n",
    "        self.chkpt_dir = chkpt_dir\n",
    "        self.act_space = [i for i in range(num_acts)]\n",
    "        self.learn_cnt = 0\n",
    "\n",
    "        self.memory = ReplayBuffer(mem_size, obs_dims)\n",
    "        self.q_eval = DeepQNetwork(self.obs_dims, self.num_acts, self.lr)\n",
    "        self.q_next = DeepQNetwork(self.obs_dims, self.num_acts, self.lr)\n",
    "        \n",
    "        \n",
    "    def choose_act(self, obs):\n",
    "        \"\"\"\n",
    "        obs :: torch tensor shape==(3, 96, 96)\n",
    "        \"\"\"\n",
    "        if np.random.random() > self.epsilon:\n",
    "            acts = self.q_eval.forward(obs.unsqueeze(0))\n",
    "            act = torch.argmax(acts).item()\n",
    "        else:\n",
    "            act = np.random.choice(self.act_space)\n",
    "\n",
    "        return int(act)\n",
    "    \n",
    "    \n",
    "    def store_transition(self, obs, act, rew, next_obs, done):\n",
    "        self.memory.push(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        \n",
    "    def sample_memory(self):\n",
    "        obs, act, rew, next_obs, done = self.memory.sample(self.batch_size)\n",
    "        return obs, act, rew, next_obs, done\n",
    "    \n",
    "    \n",
    "    def replace_target_network(self):\n",
    "        if self.learn_cnt % self.replace_target_cnt == 0:\n",
    "            self.q_next.load_state_dict(self.q_eval.state_dict())\n",
    "\n",
    "            \n",
    "    def decrement_epsilon(self):\n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min\n",
    "        \n",
    "    \n",
    "    def learn(self):\n",
    "        if self.memory.cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        self.q_eval.optimizer.zero_grad()\n",
    "\n",
    "        self.replace_target_network()\n",
    "\n",
    "        obs, act, rew, next_obs, done = self.sample_memory()\n",
    "        indxs = np.arange(self.batch_size)\n",
    "\n",
    "        q_pred = self.q_eval.forward(obs)[indxs, act]\n",
    "        q_next = self.q_next.forward(next_obs).max(dim=1)[0]\n",
    "\n",
    "        q_next[done] = 0.0\n",
    "        q_target = rew + self.gamma * q_next\n",
    "\n",
    "        loss = self.q_eval.loss(q_target, q_pred)\n",
    "        loss.backward()\n",
    "        self.q_eval.optimizer.step()\n",
    "        self.learn_cnt += 1\n",
    "\n",
    "        self.decrement_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personalized-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_iter, env, agent1, agent2):\n",
    "    \n",
    "    obs_list = env.get_obs()\n",
    "    obs1 = torch.tensor(obs_list[0], dtype=torch.float).permute(2, 0, 1)\n",
    "    obs2 = torch.tensor(obs_list[1], dtype=torch.float).permute(2, 0, 1)\n",
    "    \n",
    "    last_100_rew = [0 for i in range(100)]\n",
    "    for i in range(max_iter):\n",
    "        act1 = agent1.choose_act(obs1)\n",
    "        act2 = agent2.choose_act(obs2)\n",
    "        act_list = [act1, act2]\n",
    "        # print(\"iter= \", i, env.agt1_pos, env.agt2_pos, env.pig_pos, env.agt1_ori, env.agt2_ori, 'action', act1, act2)\n",
    "#         env.render()\n",
    "        rew_list, done = env.step(act_list)\n",
    "        rew1 = rew_list[0]\n",
    "        rew2 = rew_list[1]\n",
    "        # print(rew1)\n",
    "        _obs_list = env.get_obs()\n",
    "        _obs1 = torch.tensor(_obs_list[0], dtype=torch.float).permute(2, 0, 1)\n",
    "        _obs2 = torch.tensor(_obs_list[1], dtype=torch.float).permute(2, 0, 1)\n",
    "        agent1.store_transition(obs1, act1, rew1, _obs1, done)\n",
    "        agent2.store_transition(obs2, act2, rew2, _obs2, done)\n",
    "        obs1 = _obs1\n",
    "        obs2 = _obs2\n",
    "        agent1.learn()\n",
    "        agent2.learn()\n",
    "        last_100_rew[i % 100] = rew1 + rew2\n",
    "        \n",
    "        #env.plot_scene()\n",
    "        if rew1 + rew2 > 0:\n",
    "            print(\"iter= \", i)\n",
    "            print(\"Goal found!\")\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iter: {i}, Epsilon:{agent1.epsilon}, Reward: {sum(last_100_rew)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greater-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of map should be an odd integer no smaller than 7\n",
      "Iter: 0, Epsilon:1, Reward: -20\n",
      "Iter: 100, Epsilon:0.995099999999999, Reward: -580\n",
      "Iter: 200, Epsilon:0.9880999999999975, Reward: -460\n",
      "Iter: 300, Epsilon:0.9810999999999961, Reward: -640\n",
      "Iter: 400, Epsilon:0.9740999999999946, Reward: -660\n",
      "Iter: 500, Epsilon:0.9670999999999932, Reward: -640\n",
      "Iter: 600, Epsilon:0.9600999999999917, Reward: -520\n",
      "Iter: 700, Epsilon:0.9530999999999903, Reward: -420\n",
      "Iter: 800, Epsilon:0.9460999999999888, Reward: -600\n",
      "Iter: 900, Epsilon:0.9390999999999874, Reward: -820\n",
      "Iter: 1000, Epsilon:0.9320999999999859, Reward: -660\n",
      "Iter: 1100, Epsilon:0.9250999999999845, Reward: -540\n",
      "Iter: 1200, Epsilon:0.918099999999983, Reward: -400\n",
      "Iter: 1300, Epsilon:0.9110999999999816, Reward: -560\n",
      "Iter: 1400, Epsilon:0.9040999999999801, Reward: -460\n",
      "Iter: 1500, Epsilon:0.8970999999999787, Reward: -680\n",
      "Iter: 1600, Epsilon:0.8900999999999772, Reward: -480\n",
      "Iter: 1700, Epsilon:0.8830999999999758, Reward: -600\n",
      "Iter: 1800, Epsilon:0.8760999999999743, Reward: -540\n",
      "Iter: 1900, Epsilon:0.8690999999999729, Reward: -360\n",
      "Iter: 2000, Epsilon:0.8620999999999714, Reward: -540\n",
      "Iter: 2100, Epsilon:0.85509999999997, Reward: -520\n",
      "Iter: 2200, Epsilon:0.8480999999999685, Reward: -440\n",
      "Iter: 2300, Epsilon:0.8410999999999671, Reward: -380\n",
      "Iter: 2400, Epsilon:0.8340999999999656, Reward: -560\n",
      "Iter: 2500, Epsilon:0.8270999999999642, Reward: -380\n",
      "Iter: 2600, Epsilon:0.8200999999999627, Reward: -400\n",
      "Iter: 2700, Epsilon:0.8130999999999613, Reward: -440\n",
      "Iter: 2800, Epsilon:0.8060999999999598, Reward: -540\n",
      "Iter: 2900, Epsilon:0.7990999999999584, Reward: -480\n",
      "Iter: 3000, Epsilon:0.792099999999957, Reward: -460\n",
      "Iter: 3100, Epsilon:0.7850999999999555, Reward: -400\n",
      "Iter: 3200, Epsilon:0.778099999999954, Reward: -560\n",
      "Iter: 3300, Epsilon:0.7710999999999526, Reward: -440\n",
      "Iter: 3400, Epsilon:0.7640999999999512, Reward: -140\n",
      "Iter: 3500, Epsilon:0.7570999999999497, Reward: -680\n",
      "Iter: 3600, Epsilon:0.7500999999999483, Reward: -440\n",
      "Iter: 3700, Epsilon:0.7430999999999468, Reward: -420\n",
      "Iter: 3800, Epsilon:0.7360999999999454, Reward: -220\n",
      "Iter: 3900, Epsilon:0.7290999999999439, Reward: -300\n",
      "Iter: 4000, Epsilon:0.7220999999999425, Reward: -340\n",
      "Iter: 4100, Epsilon:0.715099999999941, Reward: -360\n",
      "Iter: 4200, Epsilon:0.7080999999999396, Reward: -480\n",
      "Iter: 4300, Epsilon:0.7010999999999381, Reward: -520\n",
      "Iter: 4400, Epsilon:0.6940999999999367, Reward: -420\n",
      "Iter: 4500, Epsilon:0.6870999999999352, Reward: -600\n",
      "Iter: 4600, Epsilon:0.6800999999999338, Reward: -360\n",
      "Iter: 4700, Epsilon:0.6730999999999323, Reward: -440\n",
      "Iter: 4800, Epsilon:0.6660999999999309, Reward: -360\n",
      "Iter: 4900, Epsilon:0.6590999999999294, Reward: -560\n",
      "Iter: 5000, Epsilon:0.652099999999928, Reward: -400\n",
      "Iter: 5100, Epsilon:0.6450999999999265, Reward: -300\n",
      "Iter: 5200, Epsilon:0.6380999999999251, Reward: -480\n",
      "Iter: 5300, Epsilon:0.6310999999999236, Reward: -200\n",
      "Iter: 5400, Epsilon:0.6240999999999222, Reward: -300\n",
      "Iter: 5500, Epsilon:0.6170999999999207, Reward: -280\n",
      "Iter: 5600, Epsilon:0.6100999999999193, Reward: -280\n",
      "Iter: 5700, Epsilon:0.6030999999999178, Reward: -280\n",
      "Iter: 5800, Epsilon:0.5960999999999164, Reward: -400\n",
      "Iter: 5900, Epsilon:0.5890999999999149, Reward: -380\n",
      "Iter: 6000, Epsilon:0.5820999999999135, Reward: -260\n",
      "Iter: 6100, Epsilon:0.575099999999912, Reward: -300\n",
      "Iter: 6200, Epsilon:0.5680999999999106, Reward: -360\n",
      "Iter: 6300, Epsilon:0.5610999999999091, Reward: -360\n",
      "Iter: 6400, Epsilon:0.5540999999999077, Reward: -260\n",
      "Iter: 6500, Epsilon:0.5470999999999062, Reward: -340\n",
      "Iter: 6600, Epsilon:0.5400999999999048, Reward: -260\n",
      "Iter: 6700, Epsilon:0.5330999999999033, Reward: -380\n",
      "Iter: 6800, Epsilon:0.5260999999999019, Reward: -140\n",
      "Iter: 6900, Epsilon:0.5190999999999004, Reward: -240\n",
      "Iter: 7000, Epsilon:0.512099999999899, Reward: -400\n",
      "Iter: 7100, Epsilon:0.5050999999998975, Reward: -180\n",
      "Iter: 7200, Epsilon:0.49809999999989607, Reward: -360\n",
      "Iter: 7300, Epsilon:0.4910999999998946, Reward: -140\n",
      "Iter: 7400, Epsilon:0.48409999999989317, Reward: -140\n",
      "Iter: 7500, Epsilon:0.4770999999998917, Reward: -180\n",
      "Iter: 7600, Epsilon:0.4700999999998903, Reward: -380\n",
      "Iter: 7700, Epsilon:0.4630999999998888, Reward: -180\n",
      "Iter: 7800, Epsilon:0.4560999999998874, Reward: -160\n",
      "Iter: 7900, Epsilon:0.4490999999998859, Reward: -220\n",
      "Iter: 8000, Epsilon:0.4420999999998845, Reward: -320\n",
      "Iter: 8100, Epsilon:0.435099999999883, Reward: -200\n",
      "Iter: 8200, Epsilon:0.4280999999998816, Reward: -340\n",
      "Iter: 8300, Epsilon:0.4210999999998801, Reward: -260\n",
      "Iter: 8400, Epsilon:0.4140999999998787, Reward: -120\n",
      "Iter: 8500, Epsilon:0.4070999999998772, Reward: -380\n",
      "Iter: 8600, Epsilon:0.4000999999998758, Reward: -280\n",
      "Iter: 8700, Epsilon:0.3930999999998743, Reward: -140\n",
      "Iter: 8800, Epsilon:0.3860999999998729, Reward: -300\n",
      "Iter: 8900, Epsilon:0.37909999999987143, Reward: -300\n",
      "Iter: 9000, Epsilon:0.37209999999987, Reward: -160\n",
      "Iter: 9100, Epsilon:0.36509999999986853, Reward: -280\n",
      "Iter: 9200, Epsilon:0.3580999999998671, Reward: -120\n",
      "Iter: 9300, Epsilon:0.35109999999986563, Reward: -80\n",
      "Iter: 9400, Epsilon:0.3440999999998642, Reward: -240\n",
      "Iter: 9500, Epsilon:0.33709999999986273, Reward: -120\n",
      "Iter: 9600, Epsilon:0.3300999999998613, Reward: -140\n",
      "Iter: 9700, Epsilon:0.32309999999985983, Reward: -180\n",
      "Iter: 9800, Epsilon:0.3160999999998584, Reward: -240\n",
      "Iter: 9900, Epsilon:0.30909999999985693, Reward: -140\n"
     ]
    }
   ],
   "source": [
    "env = EnvCatchPigs(7, False)\n",
    "max_iter = 10000\n",
    "\n",
    "dqn1 = DQNAgent((3,21,21), 5)\n",
    "dqn2 = DQNAgent((3,21,21), 5)\n",
    "\n",
    "train(max_iter, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dominican-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Epsilon:0.59993, Reward: 0\n",
      "Iter: 100, Epsilon:0.5929299999999985, Reward: -240\n",
      "Iter: 200, Epsilon:0.5859299999999971, Reward: -220\n",
      "Iter: 300, Epsilon:0.5789299999999956, Reward: -400\n",
      "Iter: 400, Epsilon:0.5719299999999942, Reward: -360\n",
      "Iter: 500, Epsilon:0.5649299999999927, Reward: -260\n",
      "Iter: 600, Epsilon:0.5579299999999913, Reward: -380\n",
      "Iter: 700, Epsilon:0.5509299999999898, Reward: -240\n",
      "Iter: 800, Epsilon:0.5439299999999884, Reward: -380\n",
      "Iter: 900, Epsilon:0.5369299999999869, Reward: -280\n",
      "Iter: 1000, Epsilon:0.5299299999999855, Reward: -220\n",
      "Iter: 1100, Epsilon:0.522929999999984, Reward: -540\n",
      "Iter: 1200, Epsilon:0.5159299999999826, Reward: -360\n",
      "Iter: 1300, Epsilon:0.5089299999999811, Reward: -220\n",
      "Iter: 1400, Epsilon:0.5019299999999797, Reward: -260\n",
      "Iter: 1500, Epsilon:0.4949299999999782, Reward: -200\n",
      "Iter: 1600, Epsilon:0.48792999999997677, Reward: -360\n",
      "Iter: 1700, Epsilon:0.4809299999999753, Reward: -220\n",
      "Iter: 1800, Epsilon:0.47392999999997387, Reward: -300\n",
      "Iter: 1900, Epsilon:0.4669299999999724, Reward: -220\n",
      "Iter: 2000, Epsilon:0.459929999999971, Reward: -120\n",
      "Iter: 2100, Epsilon:0.4529299999999695, Reward: -280\n",
      "Iter: 2200, Epsilon:0.4459299999999681, Reward: -180\n",
      "Iter: 2300, Epsilon:0.4389299999999666, Reward: -200\n",
      "Iter: 2400, Epsilon:0.4319299999999652, Reward: -200\n",
      "Iter: 2500, Epsilon:0.4249299999999637, Reward: -280\n",
      "Iter: 2600, Epsilon:0.4179299999999623, Reward: -280\n",
      "Iter: 2700, Epsilon:0.4109299999999608, Reward: -220\n",
      "Iter: 2800, Epsilon:0.4039299999999594, Reward: -140\n",
      "Iter: 2900, Epsilon:0.3969299999999579, Reward: -280\n",
      "Iter: 3000, Epsilon:0.3899299999999565, Reward: -280\n",
      "Iter: 3100, Epsilon:0.38292999999995503, Reward: -100\n",
      "Iter: 3200, Epsilon:0.3759299999999536, Reward: -360\n",
      "Iter: 3300, Epsilon:0.36892999999995213, Reward: -320\n",
      "Iter: 3400, Epsilon:0.3619299999999507, Reward: -180\n",
      "Iter: 3500, Epsilon:0.35492999999994923, Reward: -160\n",
      "Iter: 3600, Epsilon:0.3479299999999478, Reward: -200\n",
      "Iter: 3700, Epsilon:0.34092999999994633, Reward: -120\n",
      "Iter: 3800, Epsilon:0.3339299999999449, Reward: -140\n",
      "Iter: 3900, Epsilon:0.32692999999994343, Reward: -120\n",
      "Iter: 4000, Epsilon:0.319929999999942, Reward: -80\n",
      "Iter: 4100, Epsilon:0.31292999999994053, Reward: -200\n",
      "Iter: 4200, Epsilon:0.3059299999999391, Reward: -180\n",
      "Iter: 4300, Epsilon:0.29892999999993763, Reward: -80\n",
      "Iter: 4400, Epsilon:0.2919299999999362, Reward: -300\n",
      "Iter: 4500, Epsilon:0.28492999999993474, Reward: -200\n",
      "Iter: 4600, Epsilon:0.2779299999999333, Reward: -80\n",
      "Iter: 4700, Epsilon:0.27092999999993184, Reward: -60\n",
      "Iter: 4800, Epsilon:0.2639299999999304, Reward: -60\n",
      "Iter: 4900, Epsilon:0.25692999999992894, Reward: -160\n",
      "Iter: 5000, Epsilon:0.24992999999992754, Reward: -100\n",
      "Iter: 5100, Epsilon:0.24292999999992887, Reward: -180\n",
      "Iter: 5200, Epsilon:0.2359299999999302, Reward: -80\n",
      "Iter: 5300, Epsilon:0.22892999999993152, Reward: -120\n",
      "Iter: 5400, Epsilon:0.22192999999993285, Reward: -120\n",
      "Iter: 5500, Epsilon:0.21492999999993417, Reward: -100\n",
      "Iter: 5600, Epsilon:0.2079299999999355, Reward: -80\n",
      "Iter: 5700, Epsilon:0.20092999999993683, Reward: -160\n",
      "Iter: 5800, Epsilon:0.19392999999993815, Reward: -100\n",
      "Iter: 5900, Epsilon:0.18692999999993948, Reward: -80\n",
      "Iter: 6000, Epsilon:0.1799299999999408, Reward: -140\n",
      "Iter: 6100, Epsilon:0.17292999999994213, Reward: -60\n",
      "Iter: 6200, Epsilon:0.16592999999994346, Reward: -80\n",
      "Iter: 6300, Epsilon:0.15892999999994478, Reward: -20\n",
      "Iter: 6400, Epsilon:0.1519299999999461, Reward: -140\n",
      "Iter: 6500, Epsilon:0.14492999999994743, Reward: -60\n",
      "Iter: 6600, Epsilon:0.13792999999994876, Reward: -60\n",
      "Iter: 6700, Epsilon:0.1309299999999501, Reward: -160\n",
      "iter=  6723\n",
      "Goal found!\n",
      "Iter: 6800, Epsilon:0.12392999999995119, Reward: 960\n",
      "Iter: 6900, Epsilon:0.11692999999995113, Reward: -40\n",
      "Iter: 7000, Epsilon:0.10992999999995107, Reward: -120\n",
      "Iter: 7100, Epsilon:0.102929999999951, Reward: -120\n",
      "Iter: 7200, Epsilon:0.09592999999995094, Reward: -60\n",
      "Iter: 7300, Epsilon:0.08892999999995088, Reward: -40\n",
      "Iter: 7400, Epsilon:0.08192999999995082, Reward: -20\n",
      "Iter: 7500, Epsilon:0.07492999999995076, Reward: 0\n",
      "Iter: 7600, Epsilon:0.0679299999999507, Reward: -80\n",
      "Iter: 7700, Epsilon:0.060929999999950635, Reward: -20\n",
      "Iter: 7800, Epsilon:0.05392999999995057, Reward: 0\n",
      "Iter: 7900, Epsilon:0.04692999999995051, Reward: -20\n",
      "Iter: 8000, Epsilon:0.03992999999995045, Reward: 0\n",
      "Iter: 8100, Epsilon:0.03292999999995039, Reward: -40\n",
      "Iter: 8200, Epsilon:0.025929999999950326, Reward: 0\n",
      "Iter: 8300, Epsilon:0.018929999999950264, Reward: 0\n",
      "Iter: 8400, Epsilon:0.011929999999950203, Reward: 0\n",
      "Iter: 8500, Epsilon:0.01, Reward: 0\n",
      "Iter: 8600, Epsilon:0.01, Reward: 0\n",
      "Iter: 8700, Epsilon:0.01, Reward: 0\n",
      "Iter: 8800, Epsilon:0.01, Reward: 0\n",
      "Iter: 8900, Epsilon:0.01, Reward: 0\n",
      "Iter: 9000, Epsilon:0.01, Reward: 0\n",
      "Iter: 9100, Epsilon:0.01, Reward: 0\n",
      "Iter: 9200, Epsilon:0.01, Reward: 0\n",
      "Iter: 9300, Epsilon:0.01, Reward: 0\n",
      "Iter: 9400, Epsilon:0.01, Reward: 0\n",
      "Iter: 9500, Epsilon:0.01, Reward: -20\n",
      "Iter: 9600, Epsilon:0.01, Reward: 0\n",
      "Iter: 9700, Epsilon:0.01, Reward: -20\n",
      "Iter: 9800, Epsilon:0.01, Reward: 0\n",
      "Iter: 9900, Epsilon:0.01, Reward: -20\n"
     ]
    }
   ],
   "source": [
    "dqn1.epsilon = 0.6\n",
    "dqn2.epsilon = 0.6\n",
    "train(10000, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Epsilon:0.59993, Reward: 0\n",
      "Iter: 100, Epsilon:0.5929299999999985, Reward: -280\n",
      "Iter: 200, Epsilon:0.5859299999999971, Reward: -380\n",
      "Iter: 300, Epsilon:0.5789299999999956, Reward: -280\n",
      "Iter: 400, Epsilon:0.5719299999999942, Reward: -240\n",
      "Iter: 500, Epsilon:0.5649299999999927, Reward: -260\n",
      "Iter: 600, Epsilon:0.5579299999999913, Reward: -300\n",
      "Iter: 700, Epsilon:0.5509299999999898, Reward: -160\n",
      "Iter: 800, Epsilon:0.5439299999999884, Reward: -200\n",
      "Iter: 900, Epsilon:0.5369299999999869, Reward: -260\n",
      "Iter: 1000, Epsilon:0.5299299999999855, Reward: -280\n",
      "Iter: 1100, Epsilon:0.522929999999984, Reward: -240\n",
      "Iter: 1200, Epsilon:0.5159299999999826, Reward: -220\n",
      "Iter: 1300, Epsilon:0.5089299999999811, Reward: -280\n",
      "Iter: 1400, Epsilon:0.5019299999999797, Reward: -220\n",
      "Iter: 1500, Epsilon:0.4949299999999782, Reward: -340\n",
      "Iter: 1600, Epsilon:0.48792999999997677, Reward: -220\n",
      "Iter: 1700, Epsilon:0.4809299999999753, Reward: -340\n",
      "Iter: 1800, Epsilon:0.47392999999997387, Reward: -160\n",
      "Iter: 1900, Epsilon:0.4669299999999724, Reward: -280\n",
      "Iter: 2000, Epsilon:0.459929999999971, Reward: -320\n",
      "Iter: 2100, Epsilon:0.4529299999999695, Reward: -280\n",
      "Iter: 2200, Epsilon:0.4459299999999681, Reward: -240\n",
      "Iter: 2300, Epsilon:0.4389299999999666, Reward: -300\n",
      "Iter: 2400, Epsilon:0.4319299999999652, Reward: -300\n",
      "Iter: 2500, Epsilon:0.4249299999999637, Reward: -180\n",
      "Iter: 2600, Epsilon:0.4179299999999623, Reward: -220\n",
      "Iter: 2700, Epsilon:0.4109299999999608, Reward: -200\n",
      "Iter: 2800, Epsilon:0.4039299999999594, Reward: -220\n",
      "Iter: 2900, Epsilon:0.3969299999999579, Reward: -300\n",
      "Iter: 3000, Epsilon:0.3899299999999565, Reward: -160\n",
      "Iter: 3100, Epsilon:0.38292999999995503, Reward: -160\n",
      "Iter: 3200, Epsilon:0.3759299999999536, Reward: -220\n",
      "Iter: 3300, Epsilon:0.36892999999995213, Reward: -200\n",
      "Iter: 3400, Epsilon:0.3619299999999507, Reward: -180\n",
      "Iter: 3500, Epsilon:0.35492999999994923, Reward: -220\n",
      "Iter: 3600, Epsilon:0.3479299999999478, Reward: -180\n",
      "Iter: 3700, Epsilon:0.34092999999994633, Reward: -220\n",
      "Iter: 3800, Epsilon:0.3339299999999449, Reward: -120\n",
      "Iter: 3900, Epsilon:0.32692999999994343, Reward: -160\n",
      "Iter: 4000, Epsilon:0.319929999999942, Reward: -260\n",
      "Iter: 4100, Epsilon:0.31292999999994053, Reward: -200\n",
      "Iter: 4200, Epsilon:0.3059299999999391, Reward: -300\n",
      "Iter: 4300, Epsilon:0.29892999999993763, Reward: -120\n",
      "Iter: 4400, Epsilon:0.2919299999999362, Reward: -140\n",
      "Iter: 4500, Epsilon:0.28492999999993474, Reward: -100\n",
      "Iter: 4600, Epsilon:0.2779299999999333, Reward: -80\n",
      "Iter: 4700, Epsilon:0.27092999999993184, Reward: -80\n",
      "Iter: 4800, Epsilon:0.2639299999999304, Reward: -240\n",
      "Iter: 4900, Epsilon:0.25692999999992894, Reward: -240\n"
     ]
    }
   ],
   "source": [
    "dqn1.epsilon = 0.6\n",
    "dqn2.epsilon = 0.6\n",
    "train(5000, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guilty-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Epsilon:0.59993, Reward: 0\n",
      "Iter: 100, Epsilon:0.5929299999999985, Reward: -180\n",
      "Iter: 200, Epsilon:0.5859299999999971, Reward: -260\n",
      "Iter: 300, Epsilon:0.5789299999999956, Reward: -480\n",
      "Iter: 400, Epsilon:0.5719299999999942, Reward: -380\n",
      "Iter: 500, Epsilon:0.5649299999999927, Reward: -360\n",
      "Iter: 600, Epsilon:0.5579299999999913, Reward: -240\n",
      "Iter: 700, Epsilon:0.5509299999999898, Reward: -240\n",
      "Iter: 800, Epsilon:0.5439299999999884, Reward: -280\n",
      "Iter: 900, Epsilon:0.5369299999999869, Reward: -320\n",
      "Iter: 1000, Epsilon:0.5299299999999855, Reward: -360\n",
      "Iter: 1100, Epsilon:0.522929999999984, Reward: -140\n",
      "Iter: 1200, Epsilon:0.5159299999999826, Reward: -240\n",
      "Iter: 1300, Epsilon:0.5089299999999811, Reward: -320\n",
      "Iter: 1400, Epsilon:0.5019299999999797, Reward: -200\n",
      "Iter: 1500, Epsilon:0.4949299999999782, Reward: -460\n",
      "Iter: 1600, Epsilon:0.48792999999997677, Reward: -120\n",
      "Iter: 1700, Epsilon:0.4809299999999753, Reward: -340\n",
      "Iter: 1800, Epsilon:0.47392999999997387, Reward: -300\n",
      "Iter: 1900, Epsilon:0.4669299999999724, Reward: -300\n",
      "Iter: 2000, Epsilon:0.459929999999971, Reward: -340\n",
      "Iter: 2100, Epsilon:0.4529299999999695, Reward: -420\n",
      "Iter: 2200, Epsilon:0.4459299999999681, Reward: -260\n",
      "Iter: 2300, Epsilon:0.4389299999999666, Reward: -200\n",
      "Iter: 2400, Epsilon:0.4319299999999652, Reward: -300\n",
      "Iter: 2500, Epsilon:0.4249299999999637, Reward: -220\n",
      "Iter: 2600, Epsilon:0.4179299999999623, Reward: -160\n",
      "Iter: 2700, Epsilon:0.4109299999999608, Reward: -300\n",
      "Iter: 2800, Epsilon:0.4039299999999594, Reward: -320\n",
      "Iter: 2900, Epsilon:0.3969299999999579, Reward: -300\n",
      "Iter: 3000, Epsilon:0.3899299999999565, Reward: -160\n",
      "Iter: 3100, Epsilon:0.38292999999995503, Reward: -240\n",
      "Iter: 3200, Epsilon:0.3759299999999536, Reward: -200\n",
      "Iter: 3300, Epsilon:0.36892999999995213, Reward: -140\n",
      "iter=  3334\n",
      "Goal found!\n",
      "Iter: 3400, Epsilon:0.3619299999999507, Reward: 680\n",
      "Iter: 3500, Epsilon:0.35492999999994923, Reward: -140\n",
      "Iter: 3600, Epsilon:0.3479299999999478, Reward: -120\n",
      "Iter: 3700, Epsilon:0.34092999999994633, Reward: -200\n",
      "iter=  3704\n",
      "Goal found!\n",
      "Iter: 3800, Epsilon:0.3339299999999449, Reward: 880\n",
      "Iter: 3900, Epsilon:0.32692999999994343, Reward: -80\n",
      "Iter: 4000, Epsilon:0.319929999999942, Reward: -60\n",
      "Iter: 4100, Epsilon:0.31292999999994053, Reward: -200\n",
      "Iter: 4200, Epsilon:0.3059299999999391, Reward: -200\n",
      "Iter: 4300, Epsilon:0.29892999999993763, Reward: -220\n",
      "Iter: 4400, Epsilon:0.2919299999999362, Reward: -180\n",
      "Iter: 4500, Epsilon:0.28492999999993474, Reward: -280\n",
      "Iter: 4600, Epsilon:0.2779299999999333, Reward: -140\n",
      "Iter: 4700, Epsilon:0.27092999999993184, Reward: -180\n",
      "Iter: 4800, Epsilon:0.2639299999999304, Reward: -60\n",
      "Iter: 4900, Epsilon:0.25692999999992894, Reward: -140\n"
     ]
    }
   ],
   "source": [
    "dqn1.epsilon = 0.6\n",
    "dqn2.epsilon = 0.6\n",
    "train(5000, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "falling-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Epsilon:0.59993, Reward: -20\n",
      "Iter: 100, Epsilon:0.5929299999999985, Reward: -240\n",
      "Iter: 200, Epsilon:0.5859299999999971, Reward: -260\n",
      "Iter: 300, Epsilon:0.5789299999999956, Reward: -320\n",
      "Iter: 400, Epsilon:0.5719299999999942, Reward: -380\n",
      "Iter: 500, Epsilon:0.5649299999999927, Reward: -460\n",
      "Iter: 600, Epsilon:0.5579299999999913, Reward: -280\n",
      "Iter: 700, Epsilon:0.5509299999999898, Reward: -300\n",
      "Iter: 800, Epsilon:0.5439299999999884, Reward: -360\n",
      "Iter: 900, Epsilon:0.5369299999999869, Reward: -260\n",
      "Iter: 1000, Epsilon:0.5299299999999855, Reward: -480\n",
      "Iter: 1100, Epsilon:0.522929999999984, Reward: -420\n",
      "Iter: 1200, Epsilon:0.5159299999999826, Reward: -480\n",
      "Iter: 1300, Epsilon:0.5089299999999811, Reward: -200\n",
      "Iter: 1400, Epsilon:0.5019299999999797, Reward: -340\n",
      "Iter: 1500, Epsilon:0.4949299999999782, Reward: -280\n",
      "Iter: 1600, Epsilon:0.48792999999997677, Reward: -220\n",
      "Iter: 1700, Epsilon:0.4809299999999753, Reward: -260\n",
      "Iter: 1800, Epsilon:0.47392999999997387, Reward: -320\n",
      "Iter: 1900, Epsilon:0.4669299999999724, Reward: -380\n",
      "Iter: 2000, Epsilon:0.459929999999971, Reward: -300\n",
      "Iter: 2100, Epsilon:0.4529299999999695, Reward: -300\n",
      "Iter: 2200, Epsilon:0.4459299999999681, Reward: -280\n",
      "Iter: 2300, Epsilon:0.4389299999999666, Reward: -320\n",
      "Iter: 2400, Epsilon:0.4319299999999652, Reward: -160\n",
      "Iter: 2500, Epsilon:0.4249299999999637, Reward: -200\n",
      "Iter: 2600, Epsilon:0.4179299999999623, Reward: -240\n",
      "Iter: 2700, Epsilon:0.4109299999999608, Reward: -340\n",
      "Iter: 2800, Epsilon:0.4039299999999594, Reward: -220\n",
      "Iter: 2900, Epsilon:0.3969299999999579, Reward: -100\n",
      "Iter: 3000, Epsilon:0.3899299999999565, Reward: -180\n",
      "Iter: 3100, Epsilon:0.38292999999995503, Reward: -120\n",
      "Iter: 3200, Epsilon:0.3759299999999536, Reward: -340\n",
      "Iter: 3300, Epsilon:0.36892999999995213, Reward: -240\n",
      "Iter: 3400, Epsilon:0.3619299999999507, Reward: -220\n",
      "Iter: 3500, Epsilon:0.35492999999994923, Reward: -200\n",
      "Iter: 3600, Epsilon:0.3479299999999478, Reward: -160\n",
      "Iter: 3700, Epsilon:0.34092999999994633, Reward: -180\n",
      "Iter: 3800, Epsilon:0.3339299999999449, Reward: -100\n",
      "Iter: 3900, Epsilon:0.32692999999994343, Reward: -60\n",
      "Iter: 4000, Epsilon:0.319929999999942, Reward: -100\n",
      "Iter: 4100, Epsilon:0.31292999999994053, Reward: -140\n",
      "Iter: 4200, Epsilon:0.3059299999999391, Reward: -120\n",
      "Iter: 4300, Epsilon:0.29892999999993763, Reward: -120\n",
      "Iter: 4400, Epsilon:0.2919299999999362, Reward: -160\n",
      "Iter: 4500, Epsilon:0.28492999999993474, Reward: -140\n",
      "Iter: 4600, Epsilon:0.2779299999999333, Reward: -160\n",
      "Iter: 4700, Epsilon:0.27092999999993184, Reward: -80\n",
      "Iter: 4800, Epsilon:0.2639299999999304, Reward: -160\n",
      "Iter: 4900, Epsilon:0.25692999999992894, Reward: -160\n",
      "Iter: 5000, Epsilon:0.24992999999992754, Reward: -100\n",
      "Iter: 5100, Epsilon:0.24292999999992887, Reward: -140\n",
      "Iter: 5200, Epsilon:0.2359299999999302, Reward: -140\n",
      "Iter: 5300, Epsilon:0.22892999999993152, Reward: -100\n",
      "Iter: 5400, Epsilon:0.22192999999993285, Reward: -200\n",
      "Iter: 5500, Epsilon:0.21492999999993417, Reward: -200\n",
      "Iter: 5600, Epsilon:0.2079299999999355, Reward: -240\n",
      "Iter: 5700, Epsilon:0.20092999999993683, Reward: -20\n",
      "Iter: 5800, Epsilon:0.19392999999993815, Reward: -120\n",
      "Iter: 5900, Epsilon:0.18692999999993948, Reward: -80\n",
      "Iter: 6000, Epsilon:0.1799299999999408, Reward: -100\n",
      "Iter: 6100, Epsilon:0.17292999999994213, Reward: -120\n",
      "Iter: 6200, Epsilon:0.16592999999994346, Reward: -140\n",
      "Iter: 6300, Epsilon:0.15892999999994478, Reward: -100\n",
      "Iter: 6400, Epsilon:0.1519299999999461, Reward: -80\n",
      "Iter: 6500, Epsilon:0.14492999999994743, Reward: -60\n",
      "Iter: 6600, Epsilon:0.13792999999994876, Reward: -120\n",
      "Iter: 6700, Epsilon:0.1309299999999501, Reward: -120\n",
      "Iter: 6800, Epsilon:0.12392999999995119, Reward: 0\n",
      "Iter: 6900, Epsilon:0.11692999999995113, Reward: -80\n",
      "Iter: 7000, Epsilon:0.10992999999995107, Reward: -120\n",
      "Iter: 7100, Epsilon:0.102929999999951, Reward: -140\n",
      "Iter: 7200, Epsilon:0.09592999999995094, Reward: -120\n",
      "Iter: 7300, Epsilon:0.08892999999995088, Reward: -100\n",
      "Iter: 7400, Epsilon:0.08192999999995082, Reward: -40\n",
      "Iter: 7500, Epsilon:0.07492999999995076, Reward: -80\n",
      "Iter: 7600, Epsilon:0.0679299999999507, Reward: -40\n",
      "Iter: 7700, Epsilon:0.060929999999950635, Reward: 0\n",
      "Iter: 7800, Epsilon:0.05392999999995057, Reward: -60\n",
      "Iter: 7900, Epsilon:0.04692999999995051, Reward: -60\n",
      "Iter: 8000, Epsilon:0.03992999999995045, Reward: 0\n",
      "Iter: 8100, Epsilon:0.03292999999995039, Reward: -60\n",
      "Iter: 8200, Epsilon:0.025929999999950326, Reward: 0\n",
      "Iter: 8300, Epsilon:0.018929999999950264, Reward: 0\n",
      "Iter: 8400, Epsilon:0.011929999999950203, Reward: 0\n",
      "Iter: 8500, Epsilon:0.01, Reward: -40\n",
      "Iter: 8600, Epsilon:0.01, Reward: -20\n",
      "Iter: 8700, Epsilon:0.01, Reward: -20\n",
      "Iter: 8800, Epsilon:0.01, Reward: 0\n",
      "Iter: 8900, Epsilon:0.01, Reward: 0\n",
      "Iter: 9000, Epsilon:0.01, Reward: 0\n",
      "Iter: 9100, Epsilon:0.01, Reward: 0\n",
      "Iter: 9200, Epsilon:0.01, Reward: 0\n",
      "Iter: 9300, Epsilon:0.01, Reward: -20\n",
      "Iter: 9400, Epsilon:0.01, Reward: -20\n",
      "Iter: 9500, Epsilon:0.01, Reward: 0\n",
      "Iter: 9600, Epsilon:0.01, Reward: 0\n",
      "Iter: 9700, Epsilon:0.01, Reward: 0\n",
      "Iter: 9800, Epsilon:0.01, Reward: -20\n",
      "Iter: 9900, Epsilon:0.01, Reward: 0\n"
     ]
    }
   ],
   "source": [
    "dqn1.epsilon = 0.6\n",
    "dqn2.epsilon = 0.6\n",
    "train(10000, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-protection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Epsilon:0.599993, Reward: -20\n",
      "Iter: 100, Epsilon:0.5992930000000021, Reward: -240\n",
      "Iter: 200, Epsilon:0.5985930000000041, Reward: -220\n",
      "Iter: 300, Epsilon:0.5978930000000062, Reward: -240\n",
      "iter=  377\n",
      "Goal found!\n",
      "Iter: 400, Epsilon:0.5971930000000083, Reward: 620\n",
      "Iter: 500, Epsilon:0.5964930000000104, Reward: -360\n",
      "Iter: 600, Epsilon:0.5957930000000125, Reward: -380\n",
      "Iter: 700, Epsilon:0.5950930000000145, Reward: -240\n",
      "Iter: 800, Epsilon:0.5943930000000166, Reward: -380\n",
      "Iter: 900, Epsilon:0.5936930000000187, Reward: -400\n",
      "Iter: 1000, Epsilon:0.5929930000000208, Reward: -400\n",
      "Iter: 1100, Epsilon:0.5922930000000228, Reward: -220\n",
      "Iter: 1200, Epsilon:0.5915930000000249, Reward: -260\n",
      "Iter: 1300, Epsilon:0.590893000000027, Reward: -400\n",
      "Iter: 1400, Epsilon:0.590193000000029, Reward: -300\n",
      "Iter: 1500, Epsilon:0.5894930000000311, Reward: -320\n"
     ]
    }
   ],
   "source": [
    "dqn1.eps_dec=7e-6\n",
    "dqn2.eps_dec=7e-6\n",
    "dqn1.epsilon = 0.6\n",
    "dqn2.epsilon = 0.6\n",
    "train(100000, env, dqn1, dqn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
